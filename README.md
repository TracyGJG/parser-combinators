# parser-combinators

An example of combinators applied to processing a JSON string to validate it in accordance with the informal [specifciation](https://www.json.org/json-en.html). We might be conformant with the formal specificiations [ECMA-404](https://ecma-international.org/publications-and-standards/standards/ecma-404/) and [IETF RFC-7159](https://datatracker.ietf.org/doc/html/rfc7159.html), but that is not the purpose of this post.

There are six significant structures, any combination of which can comprise a valid JSON file/string. These include:
* Whitespace: which is largely dismissed.
* Number: which is a complicated little beasty when fractional and exponential factors are included.
* String: is delimited with double-quotes and can be a combination of printable and escaped characters.
* Value: is potentially topped and tailed with whitespace around, Numbers, Strings, Objects, Arrays (these two to be described soon) and static values of `true`, `false` and `null`.
* Arrays: are structures for containing zero to many, potentially duplicate Values (as defined above), which means they can be nested. They are delimited in square brackets `[]` and can contain whitespace or values with each value separated with a comma. Unlike in JS code, trailing commas are not supported and invalid.
* Objects: are collections of any number of unique key (string), Value pairs. Similar to Arrays, they can also be nested. Objects are delimited with curly braces `{}` with each key-value pair separated with a comma. Again, trailing commas are invalid. All keys are double-quoted string separated from the value with a colon and optional whitespace.

In addition to parsing the above structures there are also some common pattens we can parse, which includes:
* Leading digits (1-9) - aka decimals.
* Digits (0-9).
* Non-printable charactes (tabs, line-feed, carridge-return and spaces).
* Printable characters (ASCII values excluding ", \ and control codepoint in the decimal range 0 to 32 and 127).
* Escape sequences (\\, \", \/, \b, \n, \f, \l, \t).
* Unicode sequences (\u####, where # is a hexidecimal digit).

The vast potential combination of the above, especially, when including nested arrays and object, makes linear processing less practical and assuming a tree structure is more efficient.

"In Computer Science trees grow upside down", with the root at the top, leading to a trunck with branches that terminate in leaves (at the bottom - of course, where else would they be?). The analogy breaks down when you consider the possibility there could be multiple truncks but (between friends) let's not worry ourselves too much about those.

For many JS developers the tendency is to use arrow functions in preference to their more tradition counterparts. However, we need to resolve some cyclic references which requires the construction of a symbol lookup table the JS engine will use to validate functions during their first parsing/execution. Arrow functions cannot be referenced before they have been initialised reducign their utility.

## Testing

We will prepare a test harness (Node JS code) that will load a manifest (JSON) file. The manifest catalogues a collection of valid and invalid JSON files that will also form part of the test environment.

We will be confirming if the supplied test cases (JSON files) contain valid JSON or not, and if not where the error was found and its type. Our parser(s) will not be used to deserialise the JSON into JS data structures, just confirm compliance with the specification.

## Some definitions

* `Partial Application` (AP): This is a function generated by (returned from calling) another function. This is usually employed to supply some initial arguments to the execution context of the AP.
* `Pure`: describes a function that only operates on the parameters it defines and nothing outside its execution context. Consequently, it exhibits `referential transparency` and can be trusted to always return the same output for the same given input (arguments).
* `Predicate` is a function that always returns a Boolean result (true or false) for a given input.
* `Parser`, a function that attempts to match the input against a predefined pattern in order to attribute a token and therefore semantic meaning. When the input is not recognised an error will be produced it the pattern was expected or nothing may be reported if the pattern is optional.
* `Parser Combinator` accepts one or more parsers as input and produces as new parser. Combinators are used to construct compound parsers to capture the complexity of inter-dependent parsers. For instance when one parser is only valid when followed by another. This enables the basic parsers to remain simple yet have the ability to parse complicates input. Examples include (informal):
   * `Sequence` operation than takes in a list of parsers and passes the input to each in turn until either the last is performed or an error occurs.
   * `Repeat` is supplied with a single parser along with a minimum, and possibly a maximum, number of occurances. The input data is presented to the parse for each occurance or until an error is detected/reported.
   * `Run` is the function used to perform the parsing. It is first passed the collected parsers, at which point it will prepare the execution context (state, more on this in a moment) and return a new function (a partial application). This means the same parser can be used for numerous input data sets.

## Execution context (State Model)
The function returned by calling `Run` is the only one that is directly supplied with the source data. From then on in will be passed between parses as part of a State Model. Within the State Model there will also be an index into the source data where processing is to be performed. When an error is detected a suitable message will be recorded within the State Model. This means the State Model looks as follows.

```js
{
    data, // source data to be parsed.
    index: 0, // position of processing.
    error: '', // error report when detected. 
}
```

## I promise not to use RegExp
As a developer of many years, well versed in Regular Expressions for parsing data, there will be a strong temptation to call on the power of RegExp to perform low-level pattern matching. I will endevour to avoid RegExp as much as possible as this somewhat defeats the purpose of this post. 